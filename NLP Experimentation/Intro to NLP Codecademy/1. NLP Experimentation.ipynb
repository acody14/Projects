{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ace70cf-0a05-418b-8cfd-c0fc5bf3b416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "# regex for removing punctuation!\n",
    "import re\n",
    "\n",
    "# nltk preprocessing magic\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# grabbing a part of speech function:\n",
    "from part_of_speech import get_part_of_speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39733642-43b7-488c-a489-9e1dea2a801f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized text:\n",
      "['So', 'many', 'squids', 'are', 'jumping', 'out', 'of', 'suitcases', 'these', 'days', 'that', 'you', 'can', 'barely', 'go', 'anywhere', 'without', 'seeing', 'one', 'burst', 'forth', 'from', 'a', 'tightly', 'packed', 'valise', 'I', 'went', 'to', 'the', 'dentist', 'the', 'other', 'day', 'and', 'sure', 'enough', 'I', 'saw', 'an', 'angry', 'one', 'jump', 'out', 'of', 'my', 'dentist', 's', 'bag', 'within', 'minutes', 'of', 'arriving', 'She', 'hardly', 'even', 'noticed']\n",
      "\n",
      "Stemmed text:\n",
      "['so', 'mani', 'squid', 'are', 'jump', 'out', 'of', 'suitcas', 'these', 'day', 'that', 'you', 'can', 'bare', 'go', 'anywher', 'without', 'see', 'one', 'burst', 'forth', 'from', 'a', 'tightli', 'pack', 'valis', 'i', 'went', 'to', 'the', 'dentist', 'the', 'other', 'day', 'and', 'sure', 'enough', 'i', 'saw', 'an', 'angri', 'one', 'jump', 'out', 'of', 'my', 'dentist', 's', 'bag', 'within', 'minut', 'of', 'arriv', 'she', 'hardli', 'even', 'notic']\n",
      "\n",
      "Lemmatized text:\n",
      "['So', 'many', 'squid', 'be', 'jump', 'out', 'of', 'suitcase', 'these', 'day', 'that', 'you', 'can', 'barely', 'go', 'anywhere', 'without', 'see', 'one', 'burst', 'forth', 'from', 'a', 'tightly', 'pack', 'valise', 'I', 'go', 'to', 'the', 'dentist', 'the', 'other', 'day', 'and', 'sure', 'enough', 'I', 'saw', 'an', 'angry', 'one', 'jump', 'out', 'of', 'my', 'dentist', 's', 'bag', 'within', 'minute', 'of', 'arrive', 'She', 'hardly', 'even', 'notice']\n"
     ]
    }
   ],
   "source": [
    "text = \"So many squids are jumping out of suitcases these days that you can barely go anywhere without seeing one burst forth from a tightly packed valise. I went to the dentist the other day, and sure enough I saw an angry one jump out of my dentist's bag within minutes of arriving. She hardly even noticed.\"\n",
    "\n",
    "cleaned = re.sub('\\W+', ' ', text)\n",
    "tokenized = word_tokenize(cleaned)\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "stemmed = [stemmer.stem(token) for token in tokenized]\n",
    "\n",
    "## -- CHANGE these -- ##\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized = [lemmatizer.lemmatize(token,get_part_of_speech(token)) for token in tokenized]\n",
    "\n",
    "print(\"Tokenized text:\")\n",
    "print(tokenized)\n",
    "print(\"\\nStemmed text:\")\n",
    "print(stemmed)\n",
    "print(\"\\nLemmatized text:\")\n",
    "print(lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b1af9dc-5ff5-46b4-996c-f8469e42a91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    jumping                                                   \n",
      "  _____________________________________|__________________                                     \n",
      " |   |    |        |       |                              go                                  \n",
      " |   |    |        |       |     _________________________|____________                        \n",
      " |   |    |        |       |    |      |     |    |       |         without                   \n",
      " |   |    |        |       |    |      |     |    |       |            |                       \n",
      " |   |    |        |       |    |      |     |    |       |          seeing                   \n",
      " |   |    |        |       |    |      |     |    |       |            |                       \n",
      " |   |    |        |       |    |      |     |    |       |          burst                    \n",
      " |   |    |        |       |    |      |     |    |       |       _____|__________             \n",
      " |   |    |        |       |    |      |     |    |       |      |     |         from         \n",
      " |   |    |        |       |    |      |     |    |       |      |     |          |            \n",
      " |   |  squids    out      |    |      |     |    |       |      |     |        valise        \n",
      " |   |    |        |       |    |      |     |    |       |      |     |      ____|_______     \n",
      " |   |   many      of     days  |      |     |    |       |      |     |     |          packed\n",
      " |   |    |        |       |    |      |     |    |       |      |     |     |            |    \n",
      "are  .    So   suitcases these that   you   can barely anywhere one  forth   a         tightly\n",
      "\n",
      "                                      went                                               \n",
      "  _____________________________________|________________                                  \n",
      " |   |   |   |     |         |                         saw                               \n",
      " |   |   |   |     |         |          ________________|____                             \n",
      " |   |   |   |     |         |         |     |              jump                         \n",
      " |   |   |   |     |         |         |     |      _________|______________________      \n",
      " |   |   |   |     |         |         |     |     |    |    |         out          |    \n",
      " |   |   |   |     |         |         |     |     |    |    |          |           |     \n",
      " |   |   |   |     |         |         |     |     |    |    |          of        within \n",
      " |   |   |   |     |         |         |     |     |    |    |          |           |     \n",
      " |   |   |   |     to        |         |     |     |    |    |         bag       minutes \n",
      " |   |   |   |     |         |         |     |     |    |    |          |           |     \n",
      " |   |   |   |  dentist     day        |   enough  |    |    |       dentist        of   \n",
      " |   |   |   |     |      ___|____     |     |     |    |    |     _____|_____      |     \n",
      " I   ,  and  .    the   the     other  I    sure   an angry one   my          's arriving\n",
      "\n",
      "    noticed         \n",
      "  _____|__________   \n",
      "She  hardly even  . \n",
      "\n",
      "                       went                                    \n",
      "   _____________________|________________                       \n",
      "  |      |    |    to                   see                    \n",
      "  |      |    |    |     ________________|_____________         \n",
      "  |      |    |  store  |       options              likes     \n",
      "  |      |    |    |    |     _____|_____        ______|____    \n",
      "Austin today  .   the   to  the         food because   he  food\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from nltk import Tree \n",
    "\n",
    "dependency_parser = spacy.load('en_core_web_sm')\n",
    "\n",
    "text = \"So many squids are jumping out of suitcases these days that you can barely go anywhere without seeing one burst forth from a tightly packed valise. I went to the dentist the other day, and sure enough I saw an angry one jump out of my dentist's bag within minutes of arriving. She hardly even noticed.\"\n",
    "\n",
    "parsed_squids = dependency_parser(text)\n",
    "\n",
    "# Assign my_sentence a new value:\n",
    "my_sentence = \"Austin went to the store today to see the food options because he likes food.\"\n",
    "my_parsed_sentence = dependency_parser(my_sentence)\n",
    "\n",
    "def to_nltk_tree(node):\n",
    "  if node.n_lefts + node.n_rights > 0:\n",
    "    parsed_child_nodes = [to_nltk_tree(child) for child in node.children]\n",
    "    return Tree(node.orth_, parsed_child_nodes)\n",
    "  else:\n",
    "    return node.orth_\n",
    "\n",
    "for sent in parsed_squids.sents:\n",
    "  to_nltk_tree(sent.root).pretty_print()\n",
    "  \n",
    "for sent in my_parsed_sentence.sents:\n",
    " to_nltk_tree(sent.root).pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16f7648d-d7b5-4be9-8b4b-363e659bf199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn of the Screw opening paragraph\n",
    "turn_of_the_screw = \"The story had held us, round the fire, sufficiently breathless, but except the obvious remark that it was gruesome, as, on Christmas Eve in an old house, a strange tale should essentially be, I remember no comment uttered till somebody happened to say that it was the only case he had met in which such a visitation had fallen on a child. The case, I may mention, was that of an apparition in just such an old house as had gathered us for the occasion—an appearance, of a dreadful kind, to a little boy sleeping in the room with his mother and waking her up in the terror of it; waking her not to dissipate his dread and soothe him to sleep again, but to encounter also, herself, before she had succeeded in doing so, the same sight that had shaken him. It was this observation that drew from Douglas—not immediately, but later in the evening—a reply that had the interesting consequence to which I call attention. Someone else told a story not particularly effective, which I saw he was not following. This I took for a sign that he had himself something to produce and that we should only have to wait. We waited in fact till two nights later; but that same evening, before we scattered, he brought out what was in his mind.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08b29b4a-c380-464d-82c3-5eabe44ad954",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text\n",
      "The story had held us, round the fire, sufficiently breathless, but except the obvious remark that it was gruesome, as, on Christmas Eve in an old house, a strange tale should essentially be, I remember no comment uttered till somebody happened to say that it was the only case he had met in which such a visitation had fallen on a child. The case, I may mention, was that of an apparition in just such an old house as had gathered us for the occasion—an appearance, of a dreadful kind, to a little boy sleeping in the room with his mother and waking her up in the terror of it; waking her not to dissipate his dread and soothe him to sleep again, but to encounter also, herself, before she had succeeded in doing so, the same sight that had shaken him. It was this observation that drew from Douglas—not immediately, but later in the evening—a reply that had the interesting consequence to which I call attention. Someone else told a story not particularly effective, which I saw he was not following. This I took for a sign that he had himself something to produce and that we should only have to wait. We waited in fact till two nights later; but that same evening, before we scattered, he brought out what was in his mind.\n",
      "\n",
      "Cleaned Text\n",
      "the story had held us round the fire sufficiently breathless but except the obvious remark that it was gruesome as on christmas eve in an old house a strange tale should essentially be i remember no comment uttered till somebody happened to say that it was the only case he had met in which such a visitation had fallen on a child the case i may mention was that of an apparition in just such an old house as had gathered us for the occasion an appearance of a dreadful kind to a little boy sleeping in the room with his mother and waking her up in the terror of it waking her not to dissipate his dread and soothe him to sleep again but to encounter also herself before she had succeeded in doing so the same sight that had shaken him it was this observation that drew from douglas not immediately but later in the evening a reply that had the interesting consequence to which i call attention someone else told a story not particularly effective which i saw he was not following this i took for a sign that he had himself something to produce and that we should only have to wait we waited in fact till two nights later but that same evening before we scattered he brought out what was in his mind \n",
      "\n",
      "Tokenized Text\n",
      "['the', 'story', 'had', 'held', 'us', 'round', 'the', 'fire', 'sufficiently', 'breathless', 'but', 'except', 'the', 'obvious', 'remark', 'that', 'it', 'was', 'gruesome', 'as', 'on', 'christmas', 'eve', 'in', 'an', 'old', 'house', 'a', 'strange', 'tale', 'should', 'essentially', 'be', 'i', 'remember', 'no', 'comment', 'uttered', 'till', 'somebody', 'happened', 'to', 'say', 'that', 'it', 'was', 'the', 'only', 'case', 'he', 'had', 'met', 'in', 'which', 'such', 'a', 'visitation', 'had', 'fallen', 'on', 'a', 'child', 'the', 'case', 'i', 'may', 'mention', 'was', 'that', 'of', 'an', 'apparition', 'in', 'just', 'such', 'an', 'old', 'house', 'as', 'had', 'gathered', 'us', 'for', 'the', 'occasion', 'an', 'appearance', 'of', 'a', 'dreadful', 'kind', 'to', 'a', 'little', 'boy', 'sleeping', 'in', 'the', 'room', 'with', 'his', 'mother', 'and', 'waking', 'her', 'up', 'in', 'the', 'terror', 'of', 'it', 'waking', 'her', 'not', 'to', 'dissipate', 'his', 'dread', 'and', 'soothe', 'him', 'to', 'sleep', 'again', 'but', 'to', 'encounter', 'also', 'herself', 'before', 'she', 'had', 'succeeded', 'in', 'doing', 'so', 'the', 'same', 'sight', 'that', 'had', 'shaken', 'him', 'it', 'was', 'this', 'observation', 'that', 'drew', 'from', 'douglas', 'not', 'immediately', 'but', 'later', 'in', 'the', 'evening', 'a', 'reply', 'that', 'had', 'the', 'interesting', 'consequence', 'to', 'which', 'i', 'call', 'attention', 'someone', 'else', 'told', 'a', 'story', 'not', 'particularly', 'effective', 'which', 'i', 'saw', 'he', 'was', 'not', 'following', 'this', 'i', 'took', 'for', 'a', 'sign', 'that', 'he', 'had', 'himself', 'something', 'to', 'produce', 'and', 'that', 'we', 'should', 'only', 'have', 'to', 'wait', 'we', 'waited', 'in', 'fact', 'till', 'two', 'nights', 'later', 'but', 'that', 'same', 'evening', 'before', 'we', 'scattered', 'he', 'brought', 'out', 'what', 'was', 'in', 'his', 'mind']\n",
      "\n",
      "Filtered Text\n",
      "['story', 'held', 'us', 'round', 'fire', 'sufficiently', 'breathless', 'except', 'obvious', 'remark', 'gruesome', 'christmas', 'eve', 'old', 'house', 'strange', 'tale', 'essentially', 'remember', 'comment', 'uttered', 'till', 'somebody', 'happened', 'say', 'case', 'met', 'visitation', 'fallen', 'child', 'case', 'may', 'mention', 'apparition', 'old', 'house', 'gathered', 'us', 'occasion', 'appearance', 'dreadful', 'kind', 'little', 'boy', 'sleeping', 'room', 'mother', 'waking', 'terror', 'waking', 'dissipate', 'dread', 'soothe', 'sleep', 'encounter', 'also', 'succeeded', 'sight', 'shaken', 'observation', 'drew', 'douglas', 'immediately', 'later', 'evening', 'reply', 'interesting', 'consequence', 'call', 'attention', 'someone', 'else', 'told', 'story', 'particularly', 'effective', 'saw', 'following', 'took', 'sign', 'something', 'produce', 'wait', 'waited', 'fact', 'till', 'two', 'nights', 'later', 'evening', 'scattered', 'brought', 'mind']\n",
      "\n",
      "Normalized Text\n",
      "['story', 'hold', 'u', 'round', 'fire', 'sufficiently', 'breathless', 'except', 'obvious', 'remark', 'gruesome', 'christmas', 'eve', 'old', 'house', 'strange', 'tale', 'essentially', 'remember', 'comment', 'utter', 'till', 'somebody', 'happen', 'say', 'case', 'meet', 'visitation', 'fall', 'child', 'case', 'may', 'mention', 'apparition', 'old', 'house', 'gather', 'u', 'occasion', 'appearance', 'dreadful', 'kind', 'little', 'boy', 'sleeping', 'room', 'mother', 'wake', 'terror', 'wake', 'dissipate', 'dread', 'soothe', 'sleep', 'encounter', 'also', 'succeed', 'sight', 'shake', 'observation', 'draw', 'douglas', 'immediately', 'late', 'evening', 'reply', 'interest', 'consequence', 'call', 'attention', 'someone', 'else', 'tell', 'story', 'particularly', 'effective', 'saw', 'follow', 'take', 'sign', 'something', 'produce', 'wait', 'wait', 'fact', 'till', 'two', 'night', 'late', 'evening', 'scatter', 'bring', 'mind']\n",
      "\n",
      "Bag of Words\n",
      "Counter({'story': 2, 'u': 2, 'old': 2, 'house': 2, 'till': 2, 'case': 2, 'wake': 2, 'late': 2, 'evening': 2, 'wait': 2, 'hold': 1, 'round': 1, 'fire': 1, 'sufficiently': 1, 'breathless': 1, 'except': 1, 'obvious': 1, 'remark': 1, 'gruesome': 1, 'christmas': 1, 'eve': 1, 'strange': 1, 'tale': 1, 'essentially': 1, 'remember': 1, 'comment': 1, 'utter': 1, 'somebody': 1, 'happen': 1, 'say': 1, 'meet': 1, 'visitation': 1, 'fall': 1, 'child': 1, 'may': 1, 'mention': 1, 'apparition': 1, 'gather': 1, 'occasion': 1, 'appearance': 1, 'dreadful': 1, 'kind': 1, 'little': 1, 'boy': 1, 'sleeping': 1, 'room': 1, 'mother': 1, 'terror': 1, 'dissipate': 1, 'dread': 1, 'soothe': 1, 'sleep': 1, 'encounter': 1, 'also': 1, 'succeed': 1, 'sight': 1, 'shake': 1, 'observation': 1, 'draw': 1, 'douglas': 1, 'immediately': 1, 'reply': 1, 'interest': 1, 'consequence': 1, 'call': 1, 'attention': 1, 'someone': 1, 'else': 1, 'tell': 1, 'particularly': 1, 'effective': 1, 'saw': 1, 'follow': 1, 'take': 1, 'sign': 1, 'something': 1, 'produce': 1, 'fact': 1, 'two': 1, 'night': 1, 'scatter': 1, 'bring': 1, 'mind': 1})\n"
     ]
    }
   ],
   "source": [
    "#####################\n",
    "#Bag of words\n",
    "\n",
    "# importing regex and nltk\n",
    "import re, nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "# importing Counter to get word counts for bag of words\n",
    "from collections import Counter\n",
    "# importing part-of-speech function for lemmatization\n",
    "from part_of_speech import get_part_of_speech\n",
    "\n",
    "# Change text to another string:\n",
    "text = \"Austin is so cool! Let's go Austin! How does he do it. He's just so clever and smart and cool and nice and cool.\"\n",
    "text = turn_of_the_screw\n",
    "\n",
    "cleaned = re.sub('\\W+', ' ', text).lower()\n",
    "tokenized = word_tokenize(cleaned)\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "filtered = [word for word in tokenized if word not in stop_words]\n",
    "\n",
    "normalizer = WordNetLemmatizer()\n",
    "normalized = [normalizer.lemmatize(token, get_part_of_speech(token)) for token in filtered]\n",
    "\n",
    "# printing each step in the text preprocessing\n",
    "print(\"Original Text\")\n",
    "print(text)\n",
    "print(\"\\nCleaned Text\")\n",
    "print(cleaned)\n",
    "print(\"\\nTokenized Text\")\n",
    "print(tokenized)\n",
    "print(\"\\nFiltered Text\")\n",
    "print(filtered)\n",
    "print(\"\\nNormalized Text\")\n",
    "print(normalized)\n",
    "\n",
    "# Define bag_of_looking_glass_words & print:\n",
    "bag_of_looking_glass_words = Counter(normalized)\n",
    "print(\"\\nBag of Words\")\n",
    "print(bag_of_looking_glass_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98fc5986-130b-4345-aa3d-21a54a897c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking Glass Bigrams:\n",
      "[(('of', 'the'), 101), (('said', 'the'), 98), (('in', 'a'), 97), (('in', 'the'), 90), (('as', 'she'), 82), (('you', 'know'), 72), (('a', 'little'), 68), (('the', 'queen'), 67), (('said', 'alice'), 67), (('to', 'the'), 66)]\n",
      "\n",
      "Looking Glass Trigrams:\n",
      "[(('the', 'red', 'queen'), 54), (('the', 'white', 'queen'), 31), (('said', 'in', 'a'), 21), (('she', 'went', 'on'), 18), (('said', 'the', 'red'), 17), (('thought', 'to', 'herself'), 16), (('the', 'queen', 'said'), 16), (('said', 'to', 'herself'), 14), (('said', 'humpty', 'dumpty'), 14), (('the', 'knight', 'said'), 14)]\n",
      "\n",
      "Looking Glass n-grams:\n",
      "[(('said', 'the', 'red', 'queen'), 15), (('she', 'said', 'to', 'herself'), 11), (('alice', 'thought', 'to', 'herself'), 9), (('to', 'herself', 'as', 'she'), 9), (('one', 'and', 'one', 'and'), 8), (('and', 'one', 'and', 'one'), 8), (('alice', 'said', 'in', 'a'), 6), (('for', 'a', 'minute', 'or'), 6), (('a', 'minute', 'or', 'two'), 6), (('in', 'a', 'tone', 'of'), 6)]\n"
     ]
    }
   ],
   "source": [
    "import nltk, re\n",
    "from nltk.tokenize import word_tokenize\n",
    "# importing ngrams module from nltk\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "from looking_glass import looking_glass_full_text\n",
    "\n",
    "cleaned = re.sub('\\W+', ' ', looking_glass_full_text).lower()\n",
    "tokenized = word_tokenize(cleaned)\n",
    "\n",
    "# Change the n value to 2:\n",
    "looking_glass_bigrams = ngrams(tokenized, 2)\n",
    "looking_glass_bigrams_frequency = Counter(looking_glass_bigrams)\n",
    "\n",
    "# Change the n value to 3:\n",
    "looking_glass_trigrams = ngrams(tokenized, 3)\n",
    "looking_glass_trigrams_frequency = Counter(looking_glass_trigrams)\n",
    "\n",
    "# Change the n value to a number greater than 3:\n",
    "looking_glass_ngrams = ngrams(tokenized, 4)\n",
    "looking_glass_ngrams_frequency = Counter(looking_glass_ngrams)\n",
    "\n",
    "print(\"Looking Glass Bigrams:\")\n",
    "print(looking_glass_bigrams_frequency.most_common(10))\n",
    "\n",
    "print(\"\\nLooking Glass Trigrams:\")\n",
    "print(looking_glass_trigrams_frequency.most_common(10))\n",
    "\n",
    "print(\"\\nLooking Glass n-grams:\")\n",
    "print(looking_glass_ngrams_frequency.most_common(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
